{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from scipy.cluster import hierarchy\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Cluster_vectors:\n",
    "    def create_clusters(self, vectors, min_distance=0.4, metric=\"cosine\", criterion=\"distance\",\n",
    "                        reindex_clusters=True, count_merge=1, min_count_in_cluster=5, k=20):\n",
    "        Z = hierarchy.linkage(vectors, \"average\", metric)  # hierarchy between similarities\n",
    "        clusters = hierarchy.fcluster(Z, min_distance, criterion)  # clusters\n",
    "\n",
    "        for i in range(count_merge):\n",
    "            clusters = self.merge_clusters(clusters, vectors, min_distance, k=k)\n",
    "\n",
    "        if reindex_clusters:\n",
    "            clusters = self.reindex_clusters(clusters, min_count_in_cluster)\n",
    "\n",
    "        return clusters\n",
    "\n",
    "    @staticmethod\n",
    "    def get_cluster_mean_vectors(clusters, vectors, k=20):\n",
    "        cl_df = pd.DataFrame(clusters, columns=['cluster'])\n",
    "        cl_df['index'] = cl_df.index\n",
    "        cluster_indexes = cl_df.groupby(['cluster'])['index'].apply(lambda grp: list(grp)).to_dict()\n",
    "\n",
    "        cluster_mean_vectors = {}\n",
    "        for cluster, indexes in cluster_indexes.items():\n",
    "            cluster_vectors = vectors[indexes]\n",
    "            sorted_indexes = Cluster_vectors.get_sorted_indexes(cluster_vectors)\n",
    "            vectors_to_use = cluster_vectors[sorted_indexes[:k]]\n",
    "            mean_vector = np.mean(vectors_to_use, axis=0)\n",
    "            cluster_mean_vectors[cluster] = mean_vector\n",
    "        return cluster_mean_vectors\n",
    "\n",
    "    def merge_clusters(self, clusters, vectors, min_distance=0.4, k=20):\n",
    "\n",
    "        cluster_mean_vectors = self.get_cluster_mean_vectors(clusters, vectors, k=k)\n",
    "\n",
    "        new_vectors = np.array(list(cluster_mean_vectors.values()))\n",
    "        new_clusters = self.create_clusters(new_vectors, min_distance=min_distance, count_merge=0,\n",
    "                                            reindex_clusters=False)\n",
    "        map_old_new_cluster = dict(zip(list(cluster_mean_vectors.keys()), new_clusters))\n",
    "        return pd.Series(clusters).map(map_old_new_cluster).values\n",
    "\n",
    "    @staticmethod\n",
    "    def reindex_clusters(original_clusters, min_count_in_cluster=1):\n",
    "        # start give id number from bigger clusters to smaller\n",
    "        serie_original_clusters = pd.Series(original_clusters)\n",
    "        val_count = serie_original_clusters.value_counts()\n",
    "        more_val_count = val_count[val_count >= min_count_in_cluster]\n",
    "        less_val_count = val_count[val_count < min_count_in_cluster]\n",
    "\n",
    "        cluster_map = dict(zip(more_val_count.index, range(1, len(more_val_count) + 1)))\n",
    "        cluster_map_less = {ind: -1 for ind in less_val_count.index}\n",
    "        cluster_map.update(cluster_map_less)\n",
    "        renamed_clusters = serie_original_clusters.map(cluster_map)\n",
    "        return renamed_clusters.values\n",
    "\n",
    "    @staticmethod\n",
    "    def get_sorted_indexes(cluster_vectors):\n",
    "        cos_cluster = cosine_similarity(cluster_vectors, cluster_vectors)\n",
    "        text_sim_to_text_in_cluster = cos_cluster.sum(axis=0) / cos_cluster.shape[0]\n",
    "        sorted_indexes = np.argsort(text_sim_to_text_in_cluster)[::-1]\n",
    "        return sorted_indexes\n",
    "    \n",
    "import os\n",
    "import glob\n",
    "def read_lines(fn):\n",
    "    if not os.path.exists(fn):\n",
    "        return []\n",
    "    with open(fn, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "    lines = text.split(\"\\n\")\n",
    "    if lines[-1] == '':\n",
    "        return lines[:-1]\n",
    "    else:\n",
    "        return lines\n",
    "\n",
    "def write_lines(fn, lines, mode='w'):\n",
    "    text_to_write = \"\\n\".join(list(lines)) \n",
    "    with open(fn, encoding='utf-8', mode=mode) as f:\n",
    "        f.write(text_to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering = Cluster_vectors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wl_texts = read_lines(\"../data_parallel/wi+locness/train_tgt\")\n",
    "\n",
    "with open(\"data/wl_train_tgt_embed.pickle\", \"rb\") as f:\n",
    "    wl_vectors = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34308"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wl_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8min 15s, sys: 10.2 s, total: 8min 25s\n",
      "Wall time: 8min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "wl_clusters = clustering.create_clusters(wl_vectors, min_distance=0.5, metric=\"cosine\", criterion=\"distance\",\n",
    "                        reindex_clusters=True, count_merge=0, min_count_in_cluster=5, k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    11630\n",
       " 1      599\n",
       " 2      341\n",
       " 3      307\n",
       " 4      282\n",
       " 5      239\n",
       " 6      200\n",
       " 7      197\n",
       " 8      188\n",
       " 9      165\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(wl_clusters).value_counts()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.Series(wl_texts)[pd.Series(wl_clusters) == 7].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.5 s, sys: 3.85 s, total: 26.3 s\n",
      "Wall time: 3.63 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "wl_mean_vectors = clustering.get_cluster_mean_vectors(wl_clusters, wl_vectors, k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_wl = {\n",
    "    \"vectors\": wl_vectors,\n",
    "    \"texts\": wl_texts,\n",
    "    \"clusters\": wl_clusters,\n",
    "    \"mean_vectors\": wl_mean_vectors\n",
    "}\n",
    "\n",
    "with open(\"dump_wl.pickle\", \"wb\") as f:\n",
    "    pickle.dump(dump_wl, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nucle_texts = read_lines(\"../data_parallel/nucle/nucle_tgt\")\n",
    "\n",
    "with open(\"nucle_train_tgt_embed.pickle\", \"rb\") as f:\n",
    "    nucle_vectors = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57151"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nucle_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22min 47s, sys: 34.1 s, total: 23min 21s\n",
      "Wall time: 23min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "nucle_clusters = clustering.create_clusters(nucle_vectors, min_distance=0.5, metric=\"cosine\", criterion=\"distance\",\n",
    "                        reindex_clusters=True, count_merge=0, min_count_in_cluster=5, k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1       9289\n",
       " 1       1550\n",
       " 2       1269\n",
       " 3       1038\n",
       " 4        756\n",
       "         ... \n",
       " 1614       5\n",
       " 1646       5\n",
       " 1678       5\n",
       " 1710       5\n",
       " 1711       5\n",
       "Length: 1798, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(nucle_clusters).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "nucle_mean_vectors = clustering.get_cluster_mean_vectors(nucle_clusters, nucle_vectors, k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Reference', 'Reference : 1 .', 'References :', 'References',\n",
       "       'References :', 'References :', 'References', 'Reference',\n",
       "       'References', 'Reference'], dtype=object)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(nucle_texts)[pd.Series(nucle_clusters) == 4].values[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Retrieved June 29 , 2009 , from http : //www.iisme.org/etp/HS % 20Engineering- % 20Engineering.pdf',\n",
       "       'Retrieved 14 : 47 , Sep 4 , 2009 , from http : //www.history.com/encyclopedia.do ? articleId = 201891 .',\n",
       "       'Retrieved 15 : 00 , Sep 4 , 2009 , from http : //www.history.com/encyclopedia.do ? articleId = 200465 .',\n",
       "       'Retrieved 29 June , 2009 from http : //www.iisme.org/etp/HS % 20Engineering- % 20Engineering.pdf',\n",
       "       'Retrieved September 7 , 2009 , from USTC News : { http : //news1.ustc.edu.cn/Article_Show.asp ? ArticleID = 7635 } [ HYPERLINK : http : //news1.ustc.edu.cn/Article_Show.asp ? ArticleID = 7635 ] Xin .'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(nucle_texts)[pd.Series(nucle_clusters) == 6].values[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Retrieved June 29 , 2009 , from http : //www.iisme.org/etp/HS % 20Engineering- % 20Engineering.pdf',\n",
       "       'Retrieved 14 : 47 , Sep 4 , 2009 , from http : //www.history.com/encyclopedia.do ? articleId = 201891 .',\n",
       "       'Retrieved 15 : 00 , Sep 4 , 2009 , from http : //www.history.com/encyclopedia.do ? articleId = 200465 .',\n",
       "       'Retrieved 29 June , 2009 from http : //www.iisme.org/etp/HS % 20Engineering- % 20Engineering.pdf',\n",
       "       'Retrieved September 7 , 2009 , from USTC News : { http : //news1.ustc.edu.cn/Article_Show.asp ? ArticleID = 7635 } [ HYPERLINK : http : //news1.ustc.edu.cn/Article_Show.asp ? ArticleID = 7635 ] Xin .'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(nucle_texts)[pd.Series(nucle_clusters) == 6].values[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['.', '.', '.', '', ''], dtype=object)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(nucle_texts)[pd.Series(nucle_clusters) == 15].values[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['( 2009 ) .', '( 2009 ) .', '( 2009 September 09 ) .',\n",
       "       '( 2009 ) .',\n",
       "       'Retrieved 9 September , 2009 , http : //www.water- technology.net/projects/tuas/'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(nucle_texts)[pd.Series(nucle_clusters) == 17].values[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.Series(nucle_texts)[pd.Series(nucle_clusters) == 18].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_nucle = {\n",
    "    \"vectors\": nucle_vectors,\n",
    "    \"texts\": nucle_texts,\n",
    "    \"clusters\": nucle_clusters,\n",
    "    \"mean_vectors\": nucle_mean_vectors\n",
    "}\n",
    "\n",
    "with open(\"dump_nucle.pickle\", \"wb\") as f:\n",
    "    pickle.dump(dump_nucle, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fce_texts = read_lines(\"../data_parallel/fce/fce_train_tgt\")\n",
    "\n",
    "with open(\"fce_train_tgt_embed.pickle\", \"rb\") as f:\n",
    "    fce_vectors = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28350"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fce_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 26s, sys: 6.8 s, total: 5min 33s\n",
      "Wall time: 5min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fce_clusters = clustering.create_clusters(fce_vectors, min_distance=0.5, metric=\"cosine\", criterion=\"distance\",\n",
    "                        reindex_clusters=True, count_merge=0, min_count_in_cluster=5, k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1      5029\n",
       " 1       903\n",
       " 2       753\n",
       " 3       713\n",
       " 4       673\n",
       "        ... \n",
       " 806       5\n",
       " 822       5\n",
       " 838       5\n",
       " 854       5\n",
       " 911       5\n",
       "Length: 912, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(fce_clusters).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['I have seen your programme for the trip and I think it is going to be a great trip .',\n",
       "       'Thank you very much for organising this trip and putting all your spare time and effort into it .',\n",
       "       'I assume that this fact attracted people very much .',\n",
       "       'Moreover , most of the events I went to were fantastic .',\n",
       "       \"Firstly , I would like to say that I 'm very glad to have been chosen and I will do my best for this competition .\",\n",
       "       'It was unbelievable ! ! !', 'It was an absolutely great idea .',\n",
       "       'First of all , I would like to thank you for the excellent organization of this trip which seems to be very interesting and useful for the students .',\n",
       "       'Although modern progress has made our life easier , it may also be harmful .',\n",
       "       'First of all , I wanted to thank you for giving me the first prize in your competition .'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(fce_texts)[pd.Series(fce_clusters) == 3].values[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['But when I was there , I began to make new friends that I never thought I would have , and I never imagined the way that I was going to know them either . At the beginning , I felt very strange talking with them , but now we are very good friends .',\n",
       "       'Even there , you can meet really nice people and talk with them .',\n",
       "       'On the other hand , I have met a lot of people , and they are very friendly .',\n",
       "       'I was very happy and , of course , I agreed .',\n",
       "       'When I became , first a teenager and later an adult , I got to know the majority of my friends , good friends .',\n",
       "       'It is hard to live overseas alone . Therefore , making friends from the same country means that they can help one another .',\n",
       "       'Getting along with international friends is a great way to expand your horizons .',\n",
       "       \"I enjoy it because it 's well known and easy to find partners to play with .\",\n",
       "       \"In addition , I love dealing with people . I 'm very sociable .\",\n",
       "       'They seemed happy to share their life .',\n",
       "       'But , when our mutual friend introduced her to me , I realized that she was a nice , funny person .',\n",
       "       'This is interesting because people practise solidarity .',\n",
       "       'And you enjoy yourself with your mates and experience all those special moments with them .',\n",
       "       'Moreover , I am a kind - hearted person who enjoys meeting people a lot .',\n",
       "       'I enjoy myself all the time when I am there .',\n",
       "       'I like talking to friends and I can communicate with other people .',\n",
       "       'The first day I studied at the university , I made a lot of friends .',\n",
       "       'It was an exciting day , all my friends , family â€¦ were with me .',\n",
       "       'They are together .',\n",
       "       'Our class has changed over the years , with great classmates leaving and coming . We have always been welcoming , and not least towards the new ones .',\n",
       "       'After talking with her for a few minutes , I became so happy .',\n",
       "       \"I find it appreciable : I really love to talk to the people I 'm eating with .\",\n",
       "       \"I believe that it 's a good thing to share with everyone .\",\n",
       "       'Sometimes we are with people that we love .',\n",
       "       'If you guys could share a quality , memory or any eventful time that you shared with her through video message , it would be a great favour to me .',\n",
       "       'We have been friends since we started to talk , but our friendship has changed over time .',\n",
       "       'With time we became closer friends .',\n",
       "       'They spent time together and were very happy .',\n",
       "       'They finally meet and are happy again with a lot of good friends .',\n",
       "       'Even so , now she is starting to talk more often , and when we started high school we made lots of new friends !',\n",
       "       'It still gives me great fun in the incredible company of my friends and it keeps me fit as well .',\n",
       "       'I have very good friends thanks to the Internet .',\n",
       "       'To sum up , I totally agree with making friends through the Internet .',\n",
       "       'You can get to know other countries and new individuals .',\n",
       "       'In fact , it can help them to speak with their friends more easily .',\n",
       "       'And more , I have an opportunity to meet new people .',\n",
       "       'On the one hand , I would like to talk about the fact that , with the help of the internet , we can easily stay in touch with any of our friends .',\n",
       "       'They meet new people and make friends with students from different countries .',\n",
       "       'I think that the allure of this activity is that you can meet a lot of people and share with them that experience .',\n",
       "       'I met a lot of fantastic people and I am still in touch with them .',\n",
       "       'I miss sharing things with you .',\n",
       "       'Making new friends and sharing interests with others is always an exciting part of social life .',\n",
       "       'I am particularly interested in dealing with various types of foods and meeting new people .',\n",
       "       'Meeting new people and setting up new social relationships are also the tempting point attracting me .',\n",
       "       'Nowadays , it is very common to meet new people coming from abroad who speak different languages and speak about their home countries .',\n",
       "       'Many people will find blogs and websites useful in order to meet new people .',\n",
       "       'The positive effect is that it is possible to be in contact with your friends and family whenever , wherever .',\n",
       "       'Also , it gives us the possibility to get in contact with family and friends .',\n",
       "       'I met a few nice people and had a great time with them .',\n",
       "       'I have already met many new kind people .',\n",
       "       'In addition , it is very easy to make friends and communicate with somebody .',\n",
       "       \"Secondly , if you use the Internet to meet new people , it 's a good way to find people with similar interests . You can enter an app and you can describe what you look like and someone will be interested in you .\",\n",
       "       'In conclusion , I agree that the Internet is a good way to meet friends because you can get to know a lot of people around the world .',\n",
       "       'Friends are important and make your life happier .',\n",
       "       'I am a communicative person and I often meet with my friends .',\n",
       "       'Among my acquaintances I have a reputation for being a friendly , positive and talkative woman .',\n",
       "       'Nowadays , you can chat with your friends via computer even if they are on the other side of the planet .',\n",
       "       'It is perhaps for this reason that people who climb are often couples !',\n",
       "       'There are plenty of ways to make new friends .',\n",
       "       'And meet new people !',\n",
       "       'One of the things that I enjoy the most is that you dance in a group , so you meet people and you can make friends after a while .',\n",
       "       'People who attended the event had a wonderful time .',\n",
       "       'This process makes people closer to each other , encouraging them to cooperate and become friends .',\n",
       "       'I would like to make new friends all over the world and have a great time together .',\n",
       "       'We like to talk to her because she can always bring us happiness .',\n",
       "       'It is a special chance to bring people together .',\n",
       "       'Personally , I usually get on with people pretty well and make new friends easily as I am a natural extrovert ( or so I think ) .',\n",
       "       'All in all , even despite the fact that making friends can be a struggle ( they need our time and efforts ) , they give us support and love and improve our mood when we need it most .',\n",
       "       'Secondly , I think that the members of the team give you support , love and companionship .',\n",
       "       'Sometimes the members of a group begin to be so close to you that you love them the same as if they were part of your family .',\n",
       "       'We would gladly share our excitement about the Grand Place with your students , so that they can immediately get acquainted with it as a very enjoyable place to go to .',\n",
       "       'I enjoy every moment and people love to be with me .',\n",
       "       'Because I love talking to people and spending time with them and that job gave me that opportunity .',\n",
       "       'However , I can always recover my energy after having a nice little chat with my family or friends .',\n",
       "       'Since I joined the yoga studio , I have made a lot of new friends .',\n",
       "       'Both acquiring new knowledge and making new friends make me feel happy .',\n",
       "       'Do you like to socialize and meet new people ?',\n",
       "       'It was really great to meet them and to talk with them .',\n",
       "       'I am very enthusiastic about working with children and would welcome the chance to make new friends .',\n",
       "       'At some point , all of us have benefited enormously from a real friendship .',\n",
       "       'It is surprising the amount of nice people around you sometimes , and it is a question of spending some time to realize that you now have new friends .',\n",
       "       'In order to be stronger in number , they befriended those people and they helped each other .',\n",
       "       'Gradually , we got to know each other and soon we became best friends .',\n",
       "       'They meet by chance and start a tortuous relationship as friends .',\n",
       "       'I could not have been more excited about joining my friends .',\n",
       "       'He can make friends easily .',\n",
       "       'She was a very friendly person and soon we were chatting every day .',\n",
       "       'Thanks for sharing !',\n",
       "       'Furthermore , he is very friendly and gets on well with everyone .',\n",
       "       'I enjoyed this very much , because I got the chance to meet a lot of people .',\n",
       "       \"I 'm just glad I get to enjoy every single one .\",\n",
       "       \"I 'm glad I met you and your group of overseas students .\",\n",
       "       'I am an outgoing and happy person and like to be around people .',\n",
       "       'Therefore , he decided that he was going to meet new people to begin a new life .',\n",
       "       'We made the extra effort to be friends in the past and it generally worked both ways .',\n",
       "       'With the help of computers , young people can meet new friends , find out a lot of information , take part in forums and discussions .',\n",
       "       'What surprised me more positively was the level of peer support , the cooperation and the comradeship .',\n",
       "       'We exchanged addresses and as time went on we became good friends .',\n",
       "       'While doing these activities , teenagers will easily make new friends and develop new skills .'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(wl_texts)[pd.Series(wl_clusters) == 29].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "fce_mean_vectors = clustering.get_cluster_mean_vectors(fce_clusters, fce_vectors, k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_fce = {\n",
    "    \"vectors\": fce_vectors,\n",
    "    \"texts\": fce_texts,\n",
    "    \"clusters\": fce_clusters,\n",
    "    \"mean_vectors\": fce_mean_vectors\n",
    "}\n",
    "\n",
    "with open(\"dump_fce.pickle\", \"wb\") as f:\n",
    "    pickle.dump(dump_fce, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster lang8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang8_texts_tgt = read_lines(\"../../data_parallel/lang8/lang8_tgt\")\n",
    "lang8_texts_src = read_lines(\"../../data_parallel/lang8/lang8_src\")\n",
    "\n",
    "with open(\"data/lang8_train_tgt_embed.pickle\", \"rb\") as f:\n",
    "    lang8_vectors = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1037561"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lang8_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34585.36666666667"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lang8_texts_tgt)/30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 35000\n",
    "count_processed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_src = lang8_texts_src\n",
    "text_tgt = lang8_texts_tgt\n",
    "text_vectors = lang8_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for i in tqdm(range(31)):\n",
    "    start, end = (i*batch_size, (i+1)*batch_size)\n",
    "    src_text_batch = text_src[start:end]\n",
    "    tgt_text_batch = text_tgt[start:end]\n",
    "    vectors_batch = text_vectors[start:end]\n",
    "    \n",
    "    batch_clusters = clustering.create_clusters(vectors_batch, min_distance=0.5, metric=\"cosine\", criterion=\"distance\",\n",
    "                        reindex_clusters=True, count_merge=0, min_count_in_cluster=5, k=20)\n",
    "    \n",
    "    batch_mean_vectors = clustering.get_cluster_mean_vectors(batch_clusters, vectors_batch, k=20)\n",
    "    \n",
    "    dump = {\n",
    "        \"text_src\": src_text_batch,\n",
    "        \"text_tgt\": tgt_text_batch,\n",
    "        \"vectors\": vectors_batch,\n",
    "        \"clusters\": batch_clusters,\n",
    "        \"mean_vectors\": batch_mean_vectors\n",
    "    }\n",
    "    \n",
    "    count_processed += len(tgt_text_batch)\n",
    "    \n",
    "    with open(f\"data/dump_lang8_{str(i)}.pickle\", \"wb\") as f:\n",
    "        pickle.dump(dump, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# lang8_clusters = clustering.create_clusters(lang8_vectors, min_distance=0.5, metric=\"cosine\", criterion=\"distance\",\n",
    "#                         reindex_clusters=True, count_merge=0, min_count_in_cluster=5, k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump_lang8 = {\n",
    "#     \"vectors\": lang8_vectors,\n",
    "#     \"texts\": lang8_texts,\n",
    "#     \"clusters\": lang8_clusters\n",
    "# }\n",
    "\n",
    "# with open(\"dump_lang8.pickle\", \"wb\") as f:\n",
    "#     pickle.dump(dump_lang8, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1BW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = read_lines(\"../../data_parallel/new_1bw/train_target\")\n",
    "texts = texts[:20000]\n",
    "\n",
    "with open(\"data/1bw_train_tgt_embed.pickle\", \"rb\") as f:\n",
    "    bw_vectors = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 46s, sys: 1.16 s, total: 2min 47s\n",
      "Wall time: 2min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "bw_clusters = clustering.create_clusters(bw_vectors, min_distance=0.6, metric=\"cosine\", criterion=\"distance\",\n",
    "                        reindex_clusters=True, count_merge=0, min_count_in_cluster=10, k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bw_mean_vectors = clustering.get_cluster_mean_vectors(bw_clusters, bw_vectors, k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_bw = {\n",
    "    \"vectors\": bw_vectors,\n",
    "    \"texts\": texts,\n",
    "    \"clusters\": bw_clusters,\n",
    "    \"mean_vectors\": bw_mean_vectors\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/dump_bw.pickle\", \"wb\") as f:\n",
    "    pickle.dump(dump_bw, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PIE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = read_lines(\"../../data_parallel/synthetic/a1/a1_corr_train_98.txt\")\n",
    "texts = texts[:20000]\n",
    "\n",
    "with open(\"data/pie_train_tgt_embed.pickle\", \"rb\") as f:\n",
    "    pie_vectors = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 44s, sys: 2.8 s, total: 2min 47s\n",
      "Wall time: 2min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pie_clusters = clustering.create_clusters(pie_vectors, min_distance=0.6, metric=\"cosine\", criterion=\"distance\",\n",
    "                        reindex_clusters=True, count_merge=0, min_count_in_cluster=10, k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pie_mean_vectors = clustering.get_cluster_mean_vectors(pie_clusters, pie_vectors, k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_pie = {\n",
    "    \"vectors\": pie_vectors,\n",
    "    \"texts\": texts,\n",
    "    \"clusters\": pie_clusters,\n",
    "    \"mean_vectors\": pie_mean_vectors\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/dump_pie.pickle\", \"wb\") as f:\n",
    "    pickle.dump(dump_pie, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = read_lines(\"../../data_parallel/blogs/train_tgt\")\n",
    "texts = texts[:30000]\n",
    "\n",
    "with open(\"data/blogs_train_tgt_embed.pickle\", \"rb\") as f:\n",
    "    blogs_vectors = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 27s, sys: 9.27 s, total: 6min 36s\n",
      "Wall time: 6min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "blogs_clusters = clustering.create_clusters(blogs_vectors, min_distance=0.6, metric=\"cosine\", criterion=\"distance\",\n",
    "                        reindex_clusters=True, count_merge=0, min_count_in_cluster=10, k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "blogs_mean_vectors = clustering.get_cluster_mean_vectors(blogs_clusters, blogs_vectors, k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_blogs = {\n",
    "    \"vectors\": blogs_vectors,\n",
    "    \"texts\": texts,\n",
    "    \"clusters\": blogs_clusters,\n",
    "    \"mean_vectors\": blogs_mean_vectors\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/dump_blogs.pickle\", \"wb\") as f:\n",
    "    pickle.dump(dump_blogs, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "maks_env",
   "language": "python",
   "name": "maks_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
